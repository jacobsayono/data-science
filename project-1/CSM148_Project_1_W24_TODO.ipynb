{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 24W-COM SCI-M148 Project 1\n",
        "\n",
        "Name:\n",
        "\n",
        "UID:\n",
        "\n",
        "### **Submission Guidelines (Due: Jan 29 before the class)**\n",
        "\n",
        "1. Please fill in your name and UID above.\n",
        "\n",
        "2. Please submit a **PDF printout** of your Jupyter Notebook to **Gradescope**. If you have any trouble accessing Gradescope, please let a TA know ASAP.  \n",
        "\n",
        "3. When submitting to Gradescope, you will be taken to a page that asks you to assign questions and pages. As the PDF can get long, please make sure to assign pages to corresponding questions to ensure the readers know where to look.  \n",
        "\n"
      ],
      "metadata": {
        "id": "4TUhYvhj0bqb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I86jv5N6C8W"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Welcome to **CS148 - Introduction to Data Science!** As we're planning to move through topics aggressively in this course, to start out, we'll look to do an end-to-end walkthrough of a datascience project, and then ask you to replicate the code yourself for a new dataset.\n",
        "\n",
        "**Please note: We don't expect you to fully grasp everything happening here in either code or theory. This content will be reviewed throughout the quarter. Rather we hope that by giving you the full perspective on a data science project it will better help to contextualize the pieces as they're covered in class**\n",
        "\n",
        "In that spirit, we will first work through an example project from end to end to give you a feel for the steps involved.\n",
        "\n",
        "Here are the main steps:\n",
        "\n",
        "1. Get the data\n",
        "2. Visualize the data for insights\n",
        "3. Preprocess the data for your machine learning algorithm\n",
        "4. Select a machine learning model and train it\n",
        "5. Evaluate its performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg3fJHeH6C8a"
      },
      "source": [
        "## Working with Real Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-wSp266C8b"
      },
      "source": [
        "It is best to experiment with real-data as opposed to aritifical datasets.\n",
        "\n",
        "There are many different open datasets depending on the type of problems you might be interested in!\n",
        "\n",
        "Here are a few data repositories you could check out:\n",
        "- [UCI Datasets](http://archive.ics.uci.edu/ml/)\n",
        "- [Kaggle Datasets](kaggle.com)\n",
        "- [AWS Datasets](https://registry.opendata.aws)\n",
        "\n",
        "Below we will run through an California Housing example collected from the 1990's."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiNTFDIq6C8c"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swpf-lTq8icz"
      },
      "source": [
        "We'll start by importing a series of libraries we'll be using throughout the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgqMRyD66C8d"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5) # python>=3.5\n",
        "import sklearn\n",
        "#assert sklearn.__version__ >= \"0.20\" # sklearn >= 0.20\n",
        "\n",
        "import numpy as np #numerical package in python\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt #plotting package\n",
        "\n",
        "# to make this notebook's output identical at every run\n",
        "np.random.seed(42)\n",
        "\n",
        "#matplotlib magic for inline figures\n",
        "%matplotlib inline\n",
        "import matplotlib # plotting library\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kO24ttk6C8g"
      },
      "source": [
        "## Intro to Data Exploration Using Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZyWt3hf6C8h"
      },
      "source": [
        "In this section we will load the dataset, and visualize different\n",
        "features using different types of plots.\n",
        "\n",
        "Packages we will use:\n",
        "- **[Pandas](https://pandas.pydata.org):** is a fast, flexibile and expressive data structure widely used for tabular and multidimensional datasets.\n",
        "- **[Matplotlib](https://matplotlib.org)**: is a 2d python plotting library which you can use to create quality figures (you can plot almost anything if you're willing to code it out!)\n",
        "    - other plotting libraries:[seaborn](https://seaborn.pydata.org), [ggplot2](https://ggplot2.tidyverse.org)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU0K7CPoAgHa"
      },
      "source": [
        "Note: If you're working in CoLab for this project, the CSV file first has to be loaded into the environment. This can be done manually using the sidebar menu option, or using the following code here.\n",
        "\n",
        "If you're running this notebook locally on your device, simply proceed to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7JwVJ7R-__B"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e15utDjRA4HE"
      },
      "source": [
        "We'll now begin working with Pandas. Pandas is the principle library for data management in python. It's primary mechanism of data storage is the dataframe, a two dimensional table, where each column represents a datatype, and each row a specific data element in the set.\n",
        "\n",
        "To work with dataframes, we have to first read in the csv file and convert it to a dataframe using the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl2jybAI-6er"
      },
      "outputs": [],
      "source": [
        "# We'll now import the holy grail of python datascience: Pandas!\n",
        "import pandas as pd\n",
        "housing = pd.read_csv('housing.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmZHutSt6C8i"
      },
      "outputs": [],
      "source": [
        "housing.head() # show the first few elements of the dataframe\n",
        "               # typically this is the first thing you do\n",
        "               # to see how the dataframe looks like"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr1b7Uy_6C8j"
      },
      "source": [
        "A dataset may have different types of features\n",
        "- real valued\n",
        "- Discrete (integers)\n",
        "- categorical (strings)\n",
        "- Boolean\n",
        "\n",
        "The two categorical features are essentialy the same as you can always map a categorical string/character to an integer.\n",
        "\n",
        "In the dataset example, all our features are real valued floats, except ocean proximity which is categorical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReJASadj6C8k"
      },
      "outputs": [],
      "source": [
        "# to see a concise summary of data types, null values, and counts\n",
        "# use the info() method on the dataframe\n",
        "housing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DJrUmb26C8m"
      },
      "outputs": [],
      "source": [
        "# you can access individual columns similarly\n",
        "# to accessing elements in a python dict\n",
        "housing[\"ocean_proximity\"].head() # added head() to avoid printing many columns.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiA_r00D6C8n"
      },
      "outputs": [],
      "source": [
        "# to access a particular row we can use iloc\n",
        "housing.iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-P5AEvz6C8o"
      },
      "outputs": [],
      "source": [
        "# one other function that might be useful is\n",
        "# value_counts(), which counts the number of occurences\n",
        "# for categorical features\n",
        "housing[\"ocean_proximity\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fZA8m5z6C8q"
      },
      "outputs": [],
      "source": [
        "# The describe function compiles your typical statistics for each\n",
        "# column\n",
        "housing.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVaZkoKN6C8r"
      },
      "source": [
        "#### If you want to learn about different ways of accessing elements or other functions it's useful to check out the getting started section [here](https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8JBsZKp6C8t"
      },
      "source": [
        "## Let's start visualizing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bws2U0VM6C8u"
      },
      "outputs": [],
      "source": [
        "# We can draw a histogram for each of the dataframes features\n",
        "# using the hist function\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "# save_fig(\"attribute_histogram_plots\")\n",
        "plt.show() # pandas internally uses matplotlib, and to display all the figures\n",
        "           # the show() function must be called"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FKEQ2ol6C8w"
      },
      "outputs": [],
      "source": [
        "# if you want to have a histogram on an individual feature:\n",
        "housing[\"median_income\"].hist()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qpCtP7f6C8x"
      },
      "source": [
        "We can convert a floating point feature to a categorical feature\n",
        "by binning or by defining a set of intervals.\n",
        "\n",
        "For example, to bin the\n",
        "households based on median_income we can use the pd.cut function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5ISzMn76C8y"
      },
      "outputs": [],
      "source": [
        "# assign each bin a categorical value [1, 2, 3, 4, 5] in this case.\n",
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])\n",
        "\n",
        "housing[\"income_cat\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVR7hU736C8z"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDoj1cie6C80"
      },
      "source": [
        "#### Next let's visualize the household incomes based on latitude & longitude coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEQxP7BE6C81"
      },
      "outputs": [],
      "source": [
        "## here's a not so interestting way plotting it\n",
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-tXEafc6C82"
      },
      "outputs": [],
      "source": [
        "# we can make it look a bit nicer by using the alpha parameter,\n",
        "# it simply plots less dense areas lighter.\n",
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15jyEuIA6C83"
      },
      "outputs": [],
      "source": [
        "# A more interesting plot is to color code (heatmap) the dots\n",
        "# based on income. The code below achieves this\n",
        "\n",
        "# Please note: In order for this to work, ensure that you've loaded an image\n",
        "# of california (california.png) into this directory prior to running this\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "california_img=mpimg.imread('california.png')\n",
        "ax = housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize=(10,7),\n",
        "                       s=housing['population']/100, label=\"Population\",\n",
        "                       c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n",
        "                       colorbar=False, alpha=0.4,\n",
        "                      )\n",
        "# overlay the califronia map on the plotted scatter plot\n",
        "# note: plt.imshow still refers to the most recent figure\n",
        "# that hasn't been plotted yet.\n",
        "plt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5,\n",
        "           cmap=plt.get_cmap(\"jet\"))\n",
        "plt.ylabel(\"Latitude\", fontsize=14)\n",
        "plt.xlabel(\"Longitude\", fontsize=14)\n",
        "\n",
        "# setting up heatmap colors based on median_house_value feature\n",
        "prices = housing[\"median_house_value\"]\n",
        "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
        "cb = plt.colorbar()\n",
        "cb.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
        "cb.set_label('Median House Value', fontsize=16)\n",
        "\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j9g6Sy86C84"
      },
      "source": [
        "Not suprisingly, the most expensive houses are concentrated around the San Francisco/Los Angeles areas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pFxfLoF6C85"
      },
      "source": [
        "Up until now we have only visualized feature histograms and basic statistics.\n",
        "\n",
        "When developing machine learning models the predictiveness of a feature for a particular target of intrest is what's important.\n",
        "\n",
        "It may be that only a few features are useful for the target at hand, or features may need to be augmented by applying certain transfomrations.\n",
        "\n",
        "None the less we can explore this using correlation matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWJK9zFV6C85"
      },
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mos3Iyn6C86"
      },
      "outputs": [],
      "source": [
        "# for example if the target is \"median_house_value\", most correlated features can be sorted\n",
        "# which happens to be \"median_income\". This also intuitively makes sense.\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwRZJ6-Q6C87"
      },
      "outputs": [],
      "source": [
        "# the correlation matrix for different attributes/features can also be plotted\n",
        "# some features may show a positive correlation/negative correlation or\n",
        "# it may turn out to be completely random!\n",
        "from pandas.plotting import scatter_matrix\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqNyaXFn6C88"
      },
      "outputs": [],
      "source": [
        "# median income vs median house vlue plot plot 2 in the first row of top figure\n",
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)\n",
        "plt.axis([0, 16, 0, 550000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeUxNU6Q6C9C"
      },
      "outputs": [],
      "source": [
        "# obtain new correlations\n",
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPQDRB4o6C9E"
      },
      "source": [
        "## Preparing Dastaset for ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRR-0A4s6C9G"
      },
      "source": [
        "### Dealing With Incomplete Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za_dWFbJ6C9G"
      },
      "outputs": [],
      "source": [
        "# have you noticed when looking at the dataframe summary certain rows\n",
        "# contained null values? we can't just leave them as nulls and expect our\n",
        "# model to handle them for us...\n",
        "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
        "sample_incomplete_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skAyR7NP6C9H"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1: simply drop rows that have null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl_NA_EI6C9I"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # option 2: drop the complete feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAn69emM6C9J"
      },
      "outputs": [],
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3: replace na values with median values\n",
        "sample_incomplete_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oLcDFQ7FRaL"
      },
      "source": [
        "Now that we've played around with this, lets finalize this approach by replacing the nulls in our final dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdhRHoz9FfZl"
      },
      "outputs": [],
      "source": [
        "housing[\"total_bedrooms\"].fillna(median, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBuUO5wE6C9K"
      },
      "source": [
        "Could you think of another plausible imputation for this dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4n5zInJ6C8-"
      },
      "source": [
        "### Augmenting Features\n",
        "New features can be created by combining different columns from our data set.\n",
        "\n",
        "- rooms_per_household = total_rooms / households\n",
        "- bedrooms_per_room = total_bedrooms / total_rooms\n",
        "- etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jOcWM3J6C9B"
      },
      "outputs": [],
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/(housing[\"households\"] + 1e-6)\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/(housing[\"total_rooms\"] + 1e-6)\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/(housing[\"households\"] + 1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoTwG6wX6C9D"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
        "             alpha=0.2)\n",
        "plt.axis([0, 5, 0, 520000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XikWW1huk4md"
      },
      "source": [
        "### Dealing with Non-Numeric Data\n",
        "\n",
        "So we're almost ready to feed our dataset into a machine learning model, but we're not quite there yet!\n",
        "\n",
        "Generally speaking all models can only work with numeric data, which means that if you have Categorical data you want included in your model, you'll need to do a numeric conversion. We'll explore this more later, but for now we'll take one approach to converting our `ocean_proximity` field into a numeric one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FKAyLrxe5qp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "housing['ocean_proximity'] = labelencoder.fit_transform(housing['ocean_proximity'])\n",
        "housing.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXqcAeZ66C9E"
      },
      "source": [
        "### Divide up the Dataset for Machine Learning\n",
        "\n",
        "After having cleaned your dataset you're ready to train your machine learning model.\n",
        "\n",
        "To do so you'll aim to divide your data into:\n",
        "- train set\n",
        "- test set\n",
        "\n",
        "In some cases you might also have a validation set as well for tuning hyperparameters (don't worry if you're not familiar with this term yet..)\n",
        "\n",
        "In supervised learning setting your train set and test set should contain (**feature**, **target**) tuples.\n",
        " - **feature**: is the input to your model\n",
        " - **target**: is the ground truth label\n",
        "     - when target is categorical the task is a classification task\n",
        "     - when target is floating point the task is a regression task\n",
        "     \n",
        "We will make use of **[scikit-learn](https://scikit-learn.org/stable/)** python package for preprocessing.\n",
        "\n",
        "Scikit learn is pretty well documented and if you get confused at any point simply look up the function/object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1No8RAsH6C9F"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "# let's first start by creating our train and test sets\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    train_set = housing.loc[train_index]\n",
        "    test_set = housing.loc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbWsIadU6C9F"
      },
      "outputs": [],
      "source": [
        "housing_training = train_set.drop(\"median_house_value\", axis=1) # drop labels for training set features\n",
        "                                                       # the input to the model should not contain the true label\n",
        "housing_labels = train_set[\"median_house_value\"].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zICPhxGhhIka"
      },
      "outputs": [],
      "source": [
        "housing_testing = test_set.drop(\"median_house_value\", axis=1) # drop labels for training set features\n",
        "                                                       # the input to the model should not contain the true label\n",
        "housing__test_labels = test_set[\"median_house_value\"].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me6w2z0W6C9M"
      },
      "source": [
        "### Select a model and train\n",
        "\n",
        "Once we have prepared the dataset it's time to choose a model.\n",
        "\n",
        "As our task is to predict the median_house_value (a floating value), regression is well suited for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tTA8FuV6C9N"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_training, housing_labels)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl5oAIe3nFpI"
      },
      "outputs": [],
      "source": [
        "# let's try our model on a few testing instances\n",
        "data = housing_testing.iloc[:5]\n",
        "labels = housing__test_labels.iloc[:5]\n",
        "\n",
        "print(\"Predictions:\", lin_reg.predict(data))\n",
        "print(\"Actual labels:\", list(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AY_72tv6C9P"
      },
      "source": [
        "We can evaluate our model using certain metrics, a fitting metric for regresison is the mean-squared-loss\n",
        "\n",
        "$$L(\\hat{Y}, Y) = \\frac{1}{N} \\sum_i^N (\\hat{y_i} - y_i)^2$$\n",
        "\n",
        "where $\\hat{y}$ is the predicted value, and y is the ground truth label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1rOZEd96C9Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "preds = lin_reg.predict(housing_testing)\n",
        "mse = mean_squared_error(housing__test_labels, preds)\n",
        "rmse = np.sqrt(mse)\n",
        "rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGnLDbrJKsdh"
      },
      "source": [
        "Is this a good result? What do you think an acceptable error rate is for this sort of problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQhmhQm56C9Q"
      },
      "source": [
        "# TODO: Applying the end-end ML steps to a different dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXGbHrtf6C9R"
      },
      "source": [
        "Ok now it's time to get to work! We will apply what we've learnt to another dataset (airbnb dataset). For this project we will attempt to **predict the airbnb rental price based on other features in our given dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBVsUpUG6C9R"
      },
      "source": [
        "# Visualizing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8nuR4UG6C9S"
      },
      "source": [
        "### Load the data + statistics\n",
        "\n",
        "Let's do the following set of tasks to get us warmed up:\n",
        "- load the dataset\n",
        "- display the first few rows of the data\n",
        "- drop the following columns: name, host_id, host_name, last_review, neighbourhood\n",
        "- display a summary of the statistics of the loaded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pdxRgkK6C9T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "airbnb =  pd.read_csv('AB_NYC_2019.csv') # we load the pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V9biYRK6C9T"
      },
      "outputs": [],
      "source": [
        "airbnb_drop = # WRITE YOUR CODE HERE #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8B8wZHa6C9U"
      },
      "outputs": [],
      "source": [
        "airbnb_drop.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ytuviLWMrSf"
      },
      "outputs": [],
      "source": [
        "airbnb_drop.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWmzxILhNo_5"
      },
      "source": [
        "### Some Basic Visualizations\n",
        "\n",
        "Let's try another popular python graphics library: Plotly.\n",
        "\n",
        "You can find documentation and all the examples you'll need here: [Plotly Documentation](https://plotly.com/python/basic-charts/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh3DfMGfOU4q"
      },
      "source": [
        "Let's start out by getting a better feel for the distribution of rentals in the market.\n",
        "\n",
        "####Generate a pie chart showing the distribution of rental units across NYC's 5 Buroughs (`neighbourhood_groups` in the dataset)####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BesRVQ4WM3Ly"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = # WRITE YOUR CODE HERE #\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_PuCDuB6C9V"
      },
      "source": [
        "#### Plot the total number_of_reviews per neighbourhood_group\n",
        "\n",
        "We now want to see the total number of reviews left for each neighborhood group in the form of a Bar Chart (where the X-axis is the neighbourhood group and the Y-axis is a count of review.\n",
        "\n",
        "This is a two step process:\n",
        "1.   You'll have to sum up the reviews per neighbourhood group **(hint! try using the groupby function)**\n",
        "2.   Then use Plotly to generate the graph\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi3pWfV36C9W"
      },
      "outputs": [],
      "source": [
        "neighborhood = # WRITE YOUR CODE HERE #\n",
        "neighborhood.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSmzbZmwPJ-L"
      },
      "outputs": [],
      "source": [
        "fig = # WRITE YOUR CODE HERE #\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpmghIb86C9X"
      },
      "source": [
        "### Plot a map of airbnbs throughout New York (if it gets too crowded take a subset of the data, and try to make it look nice if you can :) ).\n",
        "\n",
        "For reference you can use the Matplotlib code above to replicate this graph here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBekxjWz6C9Y"
      },
      "outputs": [],
      "source": [
        "airbnb.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYt1Le1b6C9Z"
      },
      "outputs": [],
      "source": [
        "miniairbnb = # WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrlAM6sl6C9Z"
      },
      "outputs": [],
      "source": [
        "# A more interesting plot is to color code (heatmap) the dots\n",
        "# based on income. The code below achieves this\n",
        "\n",
        "# load an image of New York\n",
        "import matplotlib.image as mpimg\n",
        "nyc_img=mpimg.imread('nyc.png', -1)\n",
        "\n",
        "# overlay the califronia map on the plotted scatter plot\n",
        "# note: plt.imshow still refers to the most recent figure\n",
        "# that hasn't been plotted yet.\n",
        "\n",
        "# WRITE YOUR CODE HERE #\n",
        "\n",
        "# setting up heatmap colors based on median_house_value feature\n",
        "prices = housing[\"median_house_value\"]\n",
        "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
        "cb = plt.colorbar()\n",
        "cb.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
        "cb.set_label('Median House Value', fontsize=16)\n",
        "\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZsO4QL5jYsy"
      },
      "source": [
        "Now try to recreate this plot using Plotly's Scatterplot functionality. Note that the increased interactivity of the plot allows for some very cool functionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnkkBtSBYgO0"
      },
      "outputs": [],
      "source": [
        "fig = # WRITE YOUR CODE HERE #\n",
        "\n",
        "import base64\n",
        "#set a local image as a background\n",
        "image_filename = 'nyc.png'\n",
        "plotly_logo = base64.b64encode(open(image_filename, 'rb').read())\n",
        "\n",
        "# WRITE YOUR CODE HERE #\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpSLAfOu6C9b"
      },
      "source": [
        "### Use Plotly to plot the average price of room types in Brooklyn who have at least 10 Reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwyLL5Grxh1K"
      },
      "source": [
        "Like with the previous example you'll have to do a little bit of data engineering before you actually generate the plot.\n",
        "\n",
        "Generally I'd recommend the following series of steps:\n",
        "1. Filter the data by neighborhood group and number of reviews to arrive at the subset of data relevant to this graph.\n",
        "2. Groupby the room type\n",
        "3. Take the mean of the price for each roomtype group\n",
        "4. FINALLY (seriously!?!?) plot the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wl4zRUC6C9d"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE #\n",
        "subgroup = #..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztyqjnfyJFk1"
      },
      "outputs": [],
      "source": [
        "subgroup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyKN0t6wIzOs"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE #\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCaN02LY6C9f"
      },
      "source": [
        "# Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox5kR3866C9g"
      },
      "outputs": [],
      "source": [
        "airbnb_drop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUrHIoAePZrG"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYGRgKhXNlld"
      },
      "source": [
        "Let's create a new binned feature, `price_cat` that will divide our dataset into quintiles (1-5) in terms of price level (you can choose the levels to assign)\n",
        "\n",
        "Do a value count to check the distribution of values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xVYRq-T6C9g"
      },
      "outputs": [],
      "source": [
        "# assign each bin a categorical value [1, 2, 3, 4, 5] in this case.\n",
        "airbnb_drop[\"price_cat\"] = # WRITE YOUR CODE HERE #\n",
        "\n",
        "airbnb_drop[\"price_cat\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afSwMlwEQTKO"
      },
      "source": [
        "### Data Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVUy9zXMOLs6"
      },
      "source": [
        "Determine if there are any null-values and impute them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0uDu6QC6C9h"
      },
      "outputs": [],
      "source": [
        "airbnb_drop.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVa2PGAA6C9i"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE #\n",
        "airbnb_drop.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzFcYAFWQh2F"
      },
      "source": [
        "### Numeric Conversions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd1FsWviQlwm"
      },
      "source": [
        "Finally, review what features in your dataset are non-numeric and convert them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkmzT5TO6C9o"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE #\n",
        "airbnb_drop.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeZ9TVyORgxH"
      },
      "source": [
        "# Prepare Data for Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECMOV4B2RuNK"
      },
      "source": [
        "Using our `StratifiedShuffleSplit` function example from above, let's split our data into a 80/20 Training/Testing split using `price_cat` to partition the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK9NB4qC6C9l"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "# let's first start by creating our train and test sets\n",
        "\n",
        "# WRITE YOUR CODE HERE #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVV4auY16C9m"
      },
      "outputs": [],
      "source": [
        "test_set.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YssX215lSu9p"
      },
      "source": [
        "Finally, remove your labels `price` and `price_cat` from your testing and training cohorts, and create separate label features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTz6cnXJ6C9n"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GskvYGZs6C9n"
      },
      "outputs": [],
      "source": [
        "training.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH_ZzkEY6C9t"
      },
      "source": [
        "# Fit a linear regression model\n",
        "\n",
        "The task is to predict the price, you could refer to the housing example on how to train and evaluate your model using **MSE**.\n",
        "Provide both **test and train set MSE values**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGo_hS-T6C9u"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE #"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}